// Copyright Â© 2019 Binance
//
// This file is part of Binance. The full Binance copyright notice, including
// terms governing use, modification, and redistribution, is contained in the
// file LICENSE at the root of the source code distribution tree.

// Translation of tss-lib-go/ecdsa/keygen/local_party.go

use crate::{
    common::{BoxError},
    crypto::vss,
    tss::{
        message::{TssMessage, ParsedMessage, MessageContent, MessageRoutingInfo},
        party::{{Party, BaseParty, base_start, base_update}},
        round::{Round, RoundError, RoundErr},
        params::Parameters,
        party_id::PartyID,
        wire::parse_wire_message,
    },
    protocols::ecdsa::keygen::{
         types::{*, messages::*},
         rounds::Round1,
    }
};
use std::{{
    collections::HashMap,
    sync::{Arc, Mutex, mpsc::{Sender, Receiver}},
    error::Error as StdError,
    fmt::{self, Debug},
}};
use anyhow::{Result, anyhow};
use log::{warn, error, info, debug};

// Concrete Party implementation

// Stores message received in each round
#[derive(Default, Clone, Debug)] // Default is important!
pub(crate) struct LocalMessageStore {
     // Use HashMap for potentially sparse messages
     // Key: Sender PartyID Index
    pub kg_round1_messages: HashMap<i32, Arc<dyn ParsedMessage>>, // KGRound1Message
    pub kg_round2_message1s: HashMap<i32, Arc<dyn ParsedMessage>>, // KGRound2Message1
    pub kg_round2_message2s: HashMap<i32, Arc<dyn ParsedMessage>>, // KGRound2Message2
    pub kg_round3_messages: HashMap<i32, Arc<dyn ParsedMessage>>, // KGRound3Message
}

// Temporary data holder for keygen rounds
#[derive(Clone, Debug)]
pub(crate) struct LocalTempData {
    pub message_store: LocalMessageStore,

    // temp data (thrown away after keygen)
    pub ui: Option<num_bigint_dig::BigInt>, // Corresponds to poly coefficient u_i
    pub kgcs: Vec<Option<Vec<u8>>>, // Commitments C_i received in Round 1
    pub vs: Option<vss::VssScheme>, // Feldman VSS scheme
    pub ssid: Option<Vec<u8>>,
    pub ssid_nonce: Option<num_bigint_dig::BigInt>,
    pub shares: Option<vss::Shares>, // Shares generated by this party
    pub decommit_poly_g: Option<(Vec<[u8; 32]>, Vec<u8>)>, // Hash decommitment (Xi, ui)
}

impl Default for LocalTempData {
    fn default() -> Self {
        Self {
            message_store: LocalMessageStore::default(),
            ui: None,
            kgcs: Vec::new(), // Initialize later based on party count
            vs: None,
            ssid: None,
            ssid_nonce: None,
            shares: None,
            decommit_poly_g: None,
        }
    }
}

/// Concrete implementation for the ECDSA Key Generation party.
pub struct LocalParty {
    base: BaseParty, // Embed the base party logic
    params: Arc<Parameters>, // Shared parameters

    // Wrap temp and data in Mutex for safe concurrent access
    temp: Arc<Mutex<LocalTempData>>,
    data: Arc<Mutex<LocalPartySaveData>>,

    // Channels for communication
    out_ch: Sender<Box<dyn TssMessage + Send>>, // Channel to send messages out
    end_ch: Sender<LocalPartySaveData>, // Channel to send final data
}

impl Debug for LocalParty {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.debug_struct("LocalParty")
         .field("party_id", &self.base.default_party_id())
         .field("base_state", &self.base.default_string())
         // Avoid logging potentially sensitive temp/data fields directly
         .finish()
    }
}

impl LocalParty {
    /// Creates a new local party for ECDSA key generation.
    ///
    /// # Arguments
    /// * `params` - The shared protocol parameters.
    /// * `out_ch` - A channel for sending outgoing messages.
    /// * `end_ch` - A channel for sending the final save data upon completion.
    /// * `optional_pre_params` - Optional pre-computed Paillier primes.
    pub fn new(
        params: Arc<Parameters>,
        out_ch: Sender<Box<dyn TssMessage + Send>>,
        end_ch: Sender<LocalPartySaveData>,
        optional_pre_params: Option<LocalPreParams>,
    ) -> Result<Self> {
        let party_count = params.party_count();
        let mut data = LocalPartySaveData::new(party_count);

        if let Some(pre_params) = optional_pre_params {
            if !pre_params.validate_with_proof() {
                 return Err(anyhow!("`optional_pre_params` failed to validate"));
            }
            data.local_pre_params = pre_params;
        }

        let party_id = params.party_id().as_ref().clone();

        let temp_data = LocalTempData { kgcs: vec![None; party_count], ..Default::default() }; // Initialize commitments vec

        let base_party = BaseParty::new(party_id, Arc::new(|| -> Arc<dyn Round> {
            // This closure needs access to self or relevant data to create Round1
            // This suggests the Round creation might need rethinking or BaseParty needs more info.
             // For now, let's assume Round1 can be created from params/data/temp handles
             // We need to pass Arcs to the round constructor.
            // PROBLEM: The closure captures `self` which is not created yet.
            // SOLUTION: Pass necessary Arcs to BaseParty::new or modify Round trait.
            // Let's defer Round1 creation to the `first_round` method.
             panic!("first_round_provider in BaseParty should not be called directly for LocalParty");
        }));

        Ok(Self {
            base: base_party,
            params,
            temp: Arc::new(Mutex::new(temp_data)),
            data: Arc::new(Mutex::new(data)),
            out_ch,
            end_ch,
        })
    }

    // Helper to access temp data (consider if this is needed or if logic goes in rounds)
     fn temp_data(&self) -> std::sync::MutexGuard<'_, LocalTempData> {
        self.temp.lock().expect("Temp data lock poisoned")
    }

    // Helper to access save data
     fn save_data(&self) -> std::sync::MutexGuard<'_, LocalPartySaveData> {
        self.data.lock().expect("Save data lock poisoned")
    }

     // Getter for the output channel (used by rounds)
    pub(crate) fn get_output_channel(&self) -> Sender<Box<dyn TssMessage + Send>> {
        self.out_ch.clone()
    }

     // Getter for the end channel (used by rounds)
    pub(crate) fn get_end_channel(&self) -> Sender<LocalPartySaveData> {
        self.end_ch.clone()
    }
}

impl Party for LocalParty {
    fn start(&self) -> Result<(), RoundError> {
        // Pass self or necessary Arcs to base_start?
        // BaseStart needs access to party_id, is_running, set_round, first_round, start...
        // Let's implement the logic here instead of calling base_start directly for now.

         info!(target: "tss-lib", party_id = ?self.party_id(), task = TASK_NAME, "protocol starting");

        // Validation already done in new()
        if self.is_running() {
            return Err(self.wrap_error(anyhow::anyhow!("could not start. party is already running"), vec![]));
        }

        let first_round = self.first_round();
        self.set_round(first_round.clone())?;

         info!(target: "tss-lib", party_id = ?self.party_id(), task = TASK_NAME, round = 1, "starting");
        let start_result = first_round.start();
         info!(target: "tss-lib", party_id = ?self.party_id(), task = TASK_NAME, round = 1, "finished initial processing");
        start_result
    }

    fn update_from_bytes(
        &self,
        wire_bytes: &[u8],
        from: &PartyID,
        is_broadcast: bool,
    ) -> Result<bool, RoundError> {
         debug!(target: "tss-lib", party_id = ?self.party_id(), from = ?from, is_broadcast, "received bytes");
        let msg = parse_wire_message(wire_bytes, from.clone(), is_broadcast)
            .map_err(|e| self.wrap_error(e, vec![from.clone()]))?;

        // Attempt to downcast Box<dyn ParsedMessage> to concrete ParsedMessageImpl if needed
        // let parsed_msg = msg.as_any().downcast_ref::<ParsedMessageImpl>().ok_or_else(...)?;
        // Or pass the boxed trait object directly
        self.update(*msg) // Box::leak(msg)? Or pass by value?
    }

    fn update(&self, msg: Box<dyn ParsedMessage>) -> Result<bool, RoundError> {
         // base_update needs access to validate_message, store_message, current_round, advance_round etc.
         // Re-implementing the logic here to work with the Mutex locks and specific types.

         self.validate_message(msg.as_ref())?; // Validate first (outside lock maybe?)

         debug!(target: "tss-lib", party_id = ?self.party_id(), message=?msg.to_string(), "update received");

         self.store_message(msg)?; // Store the message

         // Loop processing rounds like in base_update
         loop {
            let current_round_opt = self.current_round();
            if current_round_opt.is_none() {
                debug!(target: "tss-lib", party_id = ?self.party_id(), task = TASK_NAME, "Update called but party not running");
                return Ok(true); // Or error?
            }
            let current_round = current_round_opt.unwrap();
            let round_num = current_round.round_number();

            debug!(target: "tss-lib", party_id = ?self.party_id(), task = TASK_NAME, round = round_num, "running round update logic");

            current_round.update()?;

            if current_round.can_proceed() {
                 info!(target: "tss-lib", party_id = ?self.party_id(), task = TASK_NAME, round = round_num, "round finished, advancing");
                self.advance_round();

                if let Some(next_round) = self.current_round() {
                    let next_round_num = next_round.round_number();
                     info!(target: "tss-lib", party_id = ?self.party_id(), task = TASK_NAME, round = next_round_num, "starting next round");
                    next_round.start()?;
                    continue; // Continue loop for the new round
                } else {
                     // Protocol finished
                     info!(target: "tss-lib", party_id = ?self.party_id(), task = TASK_NAME, "protocol finished!");
                     // Data should have been sent via end_ch by the final round
                     return Ok(true);
                }
            } else {
                 debug!(target: "tss-lib", party_id = ?self.party_id(), task = TASK_NAME, round = round_num, "waiting for more messages");
                return Ok(true);
            }
        }
    }

    fn is_running(&self) -> bool {
        self.base.default_is_running()
    }

    fn waiting_for(&self) -> Vec<PartyID> {
        self.base.default_waiting_for()
    }

    fn validate_message(&self, msg: &dyn ParsedMessage) -> Result<bool, RoundError> {
        // Base validation
        self.base.default_validate_message(msg)?;

        // Specific validation: check sender index
        let from = msg.from();
        let max_from_idx = self.params.party_count() - 1;
        if from.index < 0 || from.index as usize > max_from_idx {
            return Err(self.wrap_error(
                anyhow!("received msg with sender index out of bounds ({})", from.index),
                 vec![from.clone()],
             ));
        }
        Ok(true)
    }

    fn store_message(&self, msg: Box<dyn ParsedMessage>) -> Result<bool, RoundError> {
        // Double check validation just in case StoreMessage is called directly
        self.validate_message(msg.as_ref())?;

        let from_p_idx = msg.from().index;
        let type_url = msg.type_url(); // Get type URL to dispatch

         debug!(target: "tss-lib", party_id = ?self.party_id(), msg_type=%type_url, from_index=%from_p_idx, "storing message");

        let mut temp_data = self.temp_data();
        let message_store = &mut temp_data.message_store;

         // Check for message type and store
         // We need the actual concrete message types defined somewhere (e.g., messages.rs)
        match type_url.as_str() { // Compare against known type URLs
            KGRound1Message::TYPE_URL => {
                message_store.kg_round1_messages.insert(from_p_idx, msg);
            }
            KGRound2Message1::TYPE_URL => {
                message_store.kg_round2_message1s.insert(from_p_idx, msg);
            }
            KGRound2Message2::TYPE_URL => {
                message_store.kg_round2_message2s.insert(from_p_idx, msg);
            }
            KGRound3Message::TYPE_URL => {
                message_store.kg_round3_messages.insert(from_p_idx, msg);
            }
            _ => {
                 warn!(target: "tss-lib", party_id = ?self.party_id(), msg_type=%type_url, "unrecognised message type ignored");
                return Ok(false); // Indicate message was not stored
            }
        }
        Ok(true)
    }

    fn first_round(&self) -> Arc<dyn Round> {
        // Create and return the initial round (Round1)
        // Pass necessary data via Arcs
         Arc::new(Round1::new(
            self.params.clone(),
            self.data.clone(),
            self.temp.clone(),
            self.out_ch.clone(),
            self.end_ch.clone(),
        ))
    }

    fn wrap_error<E: StdError + 'static>(&self, error: E, culprits: Vec<PartyID>) -> RoundError {
        self.base.default_wrap_error(error, culprits)
    }

    fn party_id(&self) -> &PartyID {
        self.base.default_party_id()
    }

    fn string(&self) -> String {
        format!("id: {}, {}", self.party_id(), self.base.default_string())
    }

    // --- BaseParty methods delegation ---
    fn set_round(&self, round: Arc<dyn Round>) -> Result<(), RoundError> {
        self.base.default_set_round(round)
    }

    fn current_round(&self) -> Option<Arc<dyn Round>> {
        self.base.default_current_round()
    }

    fn advance_round(&self) {
        self.base.default_advance_round()
    }
} 